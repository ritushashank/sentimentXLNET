{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# File Path\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-08-05T14:38:44.743664Z","iopub.execute_input":"2023-08-05T14:38:44.744034Z","iopub.status.idle":"2023-08-05T14:38:44.756963Z","shell.execute_reply.started":"2023-08-05T14:38:44.744001Z","shell.execute_reply":"2023-08-05T14:38:44.755834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Loading libraries\nimport numpy as np # provides a high-performance multidimensional array and tools for its manipulation\nimport pandas as pd # for data munging, it contains manipulation tools designed to make data analysis fast and easy\nimport re # Regular Expressions - useful for extracting information from text \nimport nltk # Natural Language Tool Kit for symbolic and statistical natural language processing\nimport spacy # processing and understanding large volumes of text\nimport string # String module contains some constants, utility function, and classes for string manipulation\nimport re\n\n# For viz\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom plotly import graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom collections import Counter\n\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\npd.options.mode.chained_assignment = None","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2023-08-05T14:38:44.759253Z","iopub.execute_input":"2023-08-05T14:38:44.759797Z","iopub.status.idle":"2023-08-05T14:38:49.148315Z","shell.execute_reply.started":"2023-08-05T14:38:44.759735Z","shell.execute_reply":"2023-08-05T14:38:49.147217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Loading File\ndf = pd.read_csv('/kaggle/input/coronavirus-tweets/Corona_tweets.csv',encoding='latin1')","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:28.150672Z","iopub.execute_input":"2023-08-05T14:47:28.151062Z","iopub.status.idle":"2023-08-05T14:47:28.376698Z","shell.execute_reply.started":"2023-08-05T14:47:28.151019Z","shell.execute_reply":"2023-08-05T14:47:28.375698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Shape of dataframe\nprint(\" Shape of training dataframe: \", df.shape)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-08-05T14:47:29.066379Z","iopub.execute_input":"2023-08-05T14:47:29.066728Z","iopub.status.idle":"2023-08-05T14:47:29.072217Z","shell.execute_reply.started":"2023-08-05T14:47:29.066695Z","shell.execute_reply":"2023-08-05T14:47:29.071143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop duplicates\ndf.drop_duplicates()\nprint(\" Shape of dataframe after dropping duplicates: \", df.shape)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-08-05T14:47:29.768160Z","iopub.execute_input":"2023-08-05T14:47:29.768507Z","iopub.status.idle":"2023-08-05T14:47:29.825010Z","shell.execute_reply.started":"2023-08-05T14:47:29.768475Z","shell.execute_reply":"2023-08-05T14:47:29.823693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Null values\n\nnull= df.isnull().sum().sort_values(ascending=False)\ntotal =df.shape[0]\npercent_missing= (df.isnull().sum()/total).sort_values(ascending=False)\n\nmissing_data= pd.concat([null, percent_missing], axis=1, keys=['Total missing', 'Percent missing'])\n\nmissing_data.reset_index(inplace=True)\nmissing_data= missing_data.rename(columns= { \"index\": \" column name\"})\n \nprint (\"Null Values in each column:\\n\", missing_data)\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-08-05T14:47:30.363326Z","iopub.execute_input":"2023-08-05T14:47:30.363717Z","iopub.status.idle":"2023-08-05T14:47:30.407496Z","shell.execute_reply.started":"2023-08-05T14:47:30.363681Z","shell.execute_reply":"2023-08-05T14:47:30.406562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install vaderSentiment","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-08-05T14:47:31.115310Z","iopub.execute_input":"2023-08-05T14:47:31.115674Z","iopub.status.idle":"2023-08-05T14:47:38.333859Z","shell.execute_reply.started":"2023-08-05T14:47:31.115638Z","shell.execute_reply":"2023-08-05T14:47:38.332663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import vaderSentiment\n# calling SentimentIntensityAnalyzer object\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\nanalyser = SentimentIntensityAnalyzer()","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:38.337646Z","iopub.execute_input":"2023-08-05T14:47:38.338036Z","iopub.status.idle":"2023-08-05T14:47:38.364533Z","shell.execute_reply.started":"2023-08-05T14:47:38.337996Z","shell.execute_reply":"2023-08-05T14:47:38.363753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# or use nltk\n\n\n#import nltk\n#nltk.download('vader_lexicon')\n#from nltk.sentiment.vader import SentimentIntensityAnalyzer\n\n#analyser = SentimentIntensityAnalyzer()","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:38.365863Z","iopub.execute_input":"2023-08-05T14:47:38.366259Z","iopub.status.idle":"2023-08-05T14:47:38.371521Z","shell.execute_reply.started":"2023-08-05T14:47:38.366218Z","shell.execute_reply":"2023-08-05T14:47:38.370426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using polarity scores for knowing the polarity of each text\ndef sentiment_analyzer_score(sentence):\n    score = analyser.polarity_scores(sentence)\n    print(\"{:-<40} {}\".format(sentence, str(score)))","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:38.373280Z","iopub.execute_input":"2023-08-05T14:47:38.373639Z","iopub.status.idle":"2023-08-05T14:47:38.382752Z","shell.execute_reply.started":"2023-08-05T14:47:38.373603Z","shell.execute_reply":"2023-08-05T14:47:38.381803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#testing the function\ntweet  = \"I would love to watch the magic show again\"\ntweet2 = \"What the hell they have made. Pathetic!\"\ntweet3 = \" I do not know what to do\"  \nprint (sentiment_analyzer_score(tweet))\nprint (sentiment_analyzer_score(tweet2))\nprint (sentiment_analyzer_score(tweet3))","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:38.387170Z","iopub.execute_input":"2023-08-05T14:47:38.387514Z","iopub.status.idle":"2023-08-05T14:47:38.395847Z","shell.execute_reply.started":"2023-08-05T14:47:38.387478Z","shell.execute_reply":"2023-08-05T14:47:38.394675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 1) Upper Case (Capitalization)\n#### Use of upper case alphabets/words indicate the increase in magnitude of the sentiment. For example, I like the fact that monsoon is over. vs I LIKE the fact that monsoon is over.","metadata":{}},{"cell_type":"code","source":"tweet  = \"I like the fact that monsoon is over\"\ntweet2 = \"I LIKE the fact that monsoon is over\"","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:38.400087Z","iopub.execute_input":"2023-08-05T14:47:38.400534Z","iopub.status.idle":"2023-08-05T14:47:38.406469Z","shell.execute_reply.started":"2023-08-05T14:47:38.400493Z","shell.execute_reply":"2023-08-05T14:47:38.405488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (sentiment_analyzer_score(tweet))\nprint (sentiment_analyzer_score(tweet2))","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:38.408229Z","iopub.execute_input":"2023-08-05T14:47:38.408661Z","iopub.status.idle":"2023-08-05T14:47:38.420715Z","shell.execute_reply.started":"2023-08-05T14:47:38.408623Z","shell.execute_reply":"2023-08-05T14:47:38.419624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The compound score increases by 13% just by capitalization","metadata":{}},{"cell_type":"markdown","source":"#### 2) Punctuation\nUse of punctuation like !, ?, etc. add to the intensity of the text.","metadata":{"trusted":true}},{"cell_type":"code","source":"tweet  = \"What is wrong with you\"\ntweet2  = \"What is wrong with you?\"\ntweet3 = \"What is wrong with you??\"","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:38.423025Z","iopub.execute_input":"2023-08-05T14:47:38.423312Z","iopub.status.idle":"2023-08-05T14:47:38.429619Z","shell.execute_reply.started":"2023-08-05T14:47:38.423285Z","shell.execute_reply":"2023-08-05T14:47:38.428535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (sentiment_analyzer_score(tweet))\nprint (sentiment_analyzer_score(tweet2))\nprint (sentiment_analyzer_score(tweet3))","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:38.431260Z","iopub.execute_input":"2023-08-05T14:47:38.432024Z","iopub.status.idle":"2023-08-05T14:47:38.444733Z","shell.execute_reply.started":"2023-08-05T14:47:38.431978Z","shell.execute_reply":"2023-08-05T14:47:38.443956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 3) Conjuctions\nConjuctions lead to shift in polarity. The latter part (after the conjuction) acts as dominant part in defining the magnitude of polarity.","metadata":{}},{"cell_type":"code","source":"tweet  = \"He is good but his mother is irritating\"\ntweet2 = \"The thai curry was bad, however pasta was delicious\"\ntweet3 = \"The thai curry was ok and pasta was delicious\"","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:38.446314Z","iopub.execute_input":"2023-08-05T14:47:38.446754Z","iopub.status.idle":"2023-08-05T14:47:38.453173Z","shell.execute_reply.started":"2023-08-05T14:47:38.446715Z","shell.execute_reply":"2023-08-05T14:47:38.452022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (sentiment_analyzer_score(tweet))\nprint (sentiment_analyzer_score(tweet2))\nprint (sentiment_analyzer_score(tweet3))","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:38.454797Z","iopub.execute_input":"2023-08-05T14:47:38.455192Z","iopub.status.idle":"2023-08-05T14:47:38.465945Z","shell.execute_reply.started":"2023-08-05T14:47:38.455154Z","shell.execute_reply":"2023-08-05T14:47:38.464563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 4) Degree modifiers\nAs the name suggests they intensify the degree in positive or negative manner as per the use.","metadata":{"trusted":true}},{"cell_type":"code","source":"tweet = \"Real Madrid's game play was good last night.\"\ntweet2 = \"Real Madrid's game play was extremely good last night.\"\ntweet3 = \"Real Madrid's game play was somewhat good last night.\"\ntweet4 = \"Real Madrid's game play was terrible last night.\"\ntweet5 = \"Real Madrid's game play was awfully terrible last night.\"","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:38.468189Z","iopub.execute_input":"2023-08-05T14:47:38.468554Z","iopub.status.idle":"2023-08-05T14:47:38.476661Z","shell.execute_reply.started":"2023-08-05T14:47:38.468518Z","shell.execute_reply":"2023-08-05T14:47:38.475679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (sentiment_analyzer_score(tweet))\nprint (sentiment_analyzer_score(tweet2))\nprint (sentiment_analyzer_score(tweet3))\nprint (sentiment_analyzer_score(tweet4))\nprint (sentiment_analyzer_score(tweet5))","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:38.478203Z","iopub.execute_input":"2023-08-05T14:47:38.478589Z","iopub.status.idle":"2023-08-05T14:47:38.489235Z","shell.execute_reply.started":"2023-08-05T14:47:38.478542Z","shell.execute_reply":"2023-08-05T14:47:38.488082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 5) Use of emoticons","metadata":{}},{"cell_type":"code","source":"tweet = \" What a fine day I am having today\"\ntweet2 = \" What a fine day I am having today :-)\"\ntweet3 = \" What a fine day I am having today :-) :-)\"","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:38.491416Z","iopub.execute_input":"2023-08-05T14:47:38.492947Z","iopub.status.idle":"2023-08-05T14:47:38.497969Z","shell.execute_reply.started":"2023-08-05T14:47:38.492887Z","shell.execute_reply":"2023-08-05T14:47:38.496978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (sentiment_analyzer_score(tweet))\nprint (sentiment_analyzer_score(tweet2))\nprint (sentiment_analyzer_score(tweet3))","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:38.500815Z","iopub.execute_input":"2023-08-05T14:47:38.501556Z","iopub.status.idle":"2023-08-05T14:47:38.510535Z","shell.execute_reply.started":"2023-08-05T14:47:38.501513Z","shell.execute_reply":"2023-08-05T14:47:38.509641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 6) Use of emojis (utf-8 encoded)","metadata":{}},{"cell_type":"code","source":"tweet = \"I love the team and how they played last night\"\ntweet2 = \"I love the team and how they played last night 💘\"\ntweet3 = \"I love the team and how they played last night 😁\"","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:38.512743Z","iopub.execute_input":"2023-08-05T14:47:38.513267Z","iopub.status.idle":"2023-08-05T14:47:38.518468Z","shell.execute_reply.started":"2023-08-05T14:47:38.513147Z","shell.execute_reply":"2023-08-05T14:47:38.517601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (sentiment_analyzer_score(tweet))\nprint (sentiment_analyzer_score(tweet2))\nprint (sentiment_analyzer_score(tweet3))","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:38.520167Z","iopub.execute_input":"2023-08-05T14:47:38.520634Z","iopub.status.idle":"2023-08-05T14:47:38.532112Z","shell.execute_reply.started":"2023-08-05T14:47:38.520595Z","shell.execute_reply":"2023-08-05T14:47:38.530872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 7) Slangs ","metadata":{}},{"cell_type":"code","source":"tweet = \"I am laughing like crazy\"\ntweet2 = \"I am laughing like crazy lmao\"\ntweet3 = \"I am laughing like crazy lol\"","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:38.533696Z","iopub.execute_input":"2023-08-05T14:47:38.534150Z","iopub.status.idle":"2023-08-05T14:47:38.539952Z","shell.execute_reply.started":"2023-08-05T14:47:38.534112Z","shell.execute_reply":"2023-08-05T14:47:38.538474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (sentiment_analyzer_score(tweet))\nprint (sentiment_analyzer_score(tweet2))\nprint (sentiment_analyzer_score(tweet3))","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:38.541505Z","iopub.execute_input":"2023-08-05T14:47:38.542171Z","iopub.status.idle":"2023-08-05T14:47:38.552846Z","shell.execute_reply.started":"2023-08-05T14:47:38.542095Z","shell.execute_reply":"2023-08-05T14:47:38.551749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 8) Use of negations ","metadata":{}},{"cell_type":"code","source":"tweet = \"He wasn't very good at the play\"\ntweet2 = \"He was not very good at the play\"","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:38.554580Z","iopub.execute_input":"2023-08-05T14:47:38.555427Z","iopub.status.idle":"2023-08-05T14:47:38.560542Z","shell.execute_reply.started":"2023-08-05T14:47:38.555389Z","shell.execute_reply":"2023-08-05T14:47:38.559483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (sentiment_analyzer_score(tweet))\nprint (sentiment_analyzer_score(tweet2))\n","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:38.562124Z","iopub.execute_input":"2023-08-05T14:47:38.562848Z","iopub.status.idle":"2023-08-05T14:47:38.573217Z","shell.execute_reply.started":"2023-08-05T14:47:38.562807Z","shell.execute_reply":"2023-08-05T14:47:38.572106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 9) Slang words as modifiers","metadata":{}},{"cell_type":"code","source":"tweet = \"He is kinda bored\"\ntweet2 = \"He is friggin bored\"","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:38.574636Z","iopub.execute_input":"2023-08-05T14:47:38.575387Z","iopub.status.idle":"2023-08-05T14:47:38.582002Z","shell.execute_reply.started":"2023-08-05T14:47:38.575343Z","shell.execute_reply":"2023-08-05T14:47:38.580999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (sentiment_analyzer_score(tweet))\nprint (sentiment_analyzer_score(tweet2))","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:38.585326Z","iopub.execute_input":"2023-08-05T14:47:38.585610Z","iopub.status.idle":"2023-08-05T14:47:38.595678Z","shell.execute_reply.started":"2023-08-05T14:47:38.585583Z","shell.execute_reply":"2023-08-05T14:47:38.594728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"4\"></a>\n    \n<font size=\"+2\" color=\"indigo\"><b>4. Data Preprocessing</b></font><br>","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"### Tokenizer\n#### We can't analyze whole sentences, we will use regex to tokenize sentences to list of words.","metadata":{}},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:38.597360Z","iopub.execute_input":"2023-08-05T14:47:38.597894Z","iopub.status.idle":"2023-08-05T14:47:38.608233Z","shell.execute_reply.started":"2023-08-05T14:47:38.597855Z","shell.execute_reply":"2023-08-05T14:47:38.607216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.rename({'reviews.text':'text'},axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:38.609898Z","iopub.execute_input":"2023-08-05T14:47:38.610686Z","iopub.status.idle":"2023-08-05T14:47:38.618570Z","shell.execute_reply.started":"2023-08-05T14:47:38.610646Z","shell.execute_reply":"2023-08-05T14:47:38.617660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.tokenize import RegexpTokenizer\ntokenizer = RegexpTokenizer(r'\\w+')\nwords_descriptions = df['text'].apply(tokenizer.tokenize)\nwords_descriptions.tail()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:38.620268Z","iopub.execute_input":"2023-08-05T14:47:38.620999Z","iopub.status.idle":"2023-08-05T14:47:39.277995Z","shell.execute_reply.started":"2023-08-05T14:47:38.620959Z","shell.execute_reply":"2023-08-05T14:47:39.277001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words_descriptions","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:39.279426Z","iopub.execute_input":"2023-08-05T14:47:39.279831Z","iopub.status.idle":"2023-08-05T14:47:39.291366Z","shell.execute_reply.started":"2023-08-05T14:47:39.279792Z","shell.execute_reply":"2023-08-05T14:47:39.290425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### When we split description into individual words, we have to create vocabulary and additionaly we can add new feature - description lengths","metadata":{}},{"cell_type":"code","source":"all_words = [word for tokens in words_descriptions for word in tokens]\ndf['description_lengths']= [len(tokens) for tokens in words_descriptions]\nVOCAB = sorted(list(set(all_words)))\nprint(\"%s words total, with a vocabulary size of %s\" % (len(all_words), len(VOCAB)))","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:39.293041Z","iopub.execute_input":"2023-08-05T14:47:39.293780Z","iopub.status.idle":"2023-08-05T14:47:39.574694Z","shell.execute_reply.started":"2023-08-05T14:47:39.293741Z","shell.execute_reply":"2023-08-05T14:47:39.573667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking most common words\nfrom collections import Counter\ncount_all_words = Counter(all_words)\ncount_all_words.most_common(100)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:39.576091Z","iopub.execute_input":"2023-08-05T14:47:39.576465Z","iopub.status.idle":"2023-08-05T14:47:39.782832Z","shell.execute_reply.started":"2023-08-05T14:47:39.576423Z","shell.execute_reply":"2023-08-05T14:47:39.781884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#### 1-gram tokenizer\nexample = 'The quick brown fox jumps over the lazy dog.'\n\n# remove the dots and make all words lower case\nclean_example = re.sub(r'\\.', '', example)\nprint(clean_example.split())","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:39.784545Z","iopub.execute_input":"2023-08-05T14:47:39.784955Z","iopub.status.idle":"2023-08-05T14:47:39.793756Z","shell.execute_reply.started":"2023-08-05T14:47:39.784899Z","shell.execute_reply":"2023-08-05T14:47:39.791215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 2-gram tokenizer\n\nexample = 'The quick brown fox jumps over the lazy dog.'\n\nwithout_first = example.split()[1:]\nwithout_last = example.split()[:-1]\n\nlist(zip(without_last, without_first))","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:39.796128Z","iopub.execute_input":"2023-08-05T14:47:39.796510Z","iopub.status.idle":"2023-08-05T14:47:39.805885Z","shell.execute_reply.started":"2023-08-05T14:47:39.796472Z","shell.execute_reply":"2023-08-05T14:47:39.804961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (sentiment_analyzer_score(tweet2))","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:39.815405Z","iopub.execute_input":"2023-08-05T14:47:39.815744Z","iopub.status.idle":"2023-08-05T14:47:39.821022Z","shell.execute_reply.started":"2023-08-05T14:47:39.815713Z","shell.execute_reply":"2023-08-05T14:47:39.820040Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['scores'] = df['text'].apply(lambda review: analyser.polarity_scores(review))\n\ndf.head()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-08-05T14:47:39.822722Z","iopub.execute_input":"2023-08-05T14:47:39.823448Z","iopub.status.idle":"2023-08-05T14:47:52.149797Z","shell.execute_reply.started":"2023-08-05T14:47:39.823407Z","shell.execute_reply":"2023-08-05T14:47:52.148944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['compound']  = df['scores'].apply(lambda score_dict: score_dict['compound'])\n\ndf.head()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-08-05T14:47:52.151331Z","iopub.execute_input":"2023-08-05T14:47:52.151694Z","iopub.status.idle":"2023-08-05T14:47:52.188308Z","shell.execute_reply.started":"2023-08-05T14:47:52.151655Z","shell.execute_reply":"2023-08-05T14:47:52.187396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Sentimnt(x):\n    if x>= 0.05:\n        return \"Positive\"\n    elif x<= -0.05:\n        return \"Negative\"\n    else:\n        return \"Neutral\"\n#df['Sentiment'] = df['compound'].apply(lambda c: 'positive' if c >=0.00  else 'negative')\ndf['Sentiment'] = df['compound'].apply(Sentimnt)\n\n\ndf.head()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-08-05T14:47:52.189713Z","iopub.execute_input":"2023-08-05T14:47:52.190313Z","iopub.status.idle":"2023-08-05T14:47:52.229812Z","shell.execute_reply.started":"2023-08-05T14:47:52.190269Z","shell.execute_reply":"2023-08-05T14:47:52.228880Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"var1 = df.groupby('Sentiment').count()['text'].reset_index().sort_values(by='text',ascending=False)\nsns.set_style(\"white\")\nsns.set_palette(\"Set2\")\nvar1.style.background_gradient()","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:52.231239Z","iopub.execute_input":"2023-08-05T14:47:52.231743Z","iopub.status.idle":"2023-08-05T14:47:52.281116Z","shell.execute_reply.started":"2023-08-05T14:47:52.231703Z","shell.execute_reply":"2023-08-05T14:47:52.280142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.countplot(x='Sentiment',data=df)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:52.282848Z","iopub.execute_input":"2023-08-05T14:47:52.283243Z","iopub.status.idle":"2023-08-05T14:47:52.455935Z","shell.execute_reply.started":"2023-08-05T14:47:52.283204Z","shell.execute_reply":"2023-08-05T14:47:52.454729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"var1['text']=var1['text']+2446","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:52.457677Z","iopub.execute_input":"2023-08-05T14:47:52.458109Z","iopub.status.idle":"2023-08-05T14:47:52.464386Z","shell.execute_reply.started":"2023-08-05T14:47:52.458060Z","shell.execute_reply":"2023-08-05T14:47:52.463228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = go.Figure(go.Funnelarea(\n    text =var1.Sentiment,\n    values = var1.text,\n    title = {\"position\": \"top center\", \"text\": \"Funnel-Chart of Sentiment Distribution\"}\n    ))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:52.466045Z","iopub.execute_input":"2023-08-05T14:47:52.466875Z","iopub.status.idle":"2023-08-05T14:47:52.487082Z","shell.execute_reply.started":"2023-08-05T14:47:52.466832Z","shell.execute_reply":"2023-08-05T14:47:52.485931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Most common words","metadata":{}},{"cell_type":"code","source":"#top(4)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:52.488565Z","iopub.execute_input":"2023-08-05T14:47:52.489166Z","iopub.status.idle":"2023-08-05T14:47:52.494304Z","shell.execute_reply.started":"2023-08-05T14:47:52.489113Z","shell.execute_reply":"2023-08-05T14:47:52.493354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['temp_list'] = df['text'].apply(lambda x:str(x).split())\ntop = Counter([item for sublist in df['temp_list'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(15))\ntemp.columns = ['Common_words','count']\n#temp.style.background_gradient(cmap='Blues')","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:52.496069Z","iopub.execute_input":"2023-08-05T14:47:52.496669Z","iopub.status.idle":"2023-08-05T14:47:53.003521Z","shell.execute_reply.started":"2023-08-05T14:47:52.496626Z","shell.execute_reply":"2023-08-05T14:47:53.002659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp['count']=temp['count']","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:53.005841Z","iopub.execute_input":"2023-08-05T14:47:53.006385Z","iopub.status.idle":"2023-08-05T14:47:53.011805Z","shell.execute_reply.started":"2023-08-05T14:47:53.006345Z","shell.execute_reply":"2023-08-05T14:47:53.010983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp.loc[(temp['Common_words']=='#coronavirus'),'Common_words']='covid_vaccine'","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:53.013330Z","iopub.execute_input":"2023-08-05T14:47:53.013857Z","iopub.status.idle":"2023-08-05T14:47:53.028108Z","shell.execute_reply.started":"2023-08-05T14:47:53.013817Z","shell.execute_reply":"2023-08-05T14:47:53.026915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.bar(temp, x=\"count\", y=\"Common_words\", title='Commmon Words in Selected Text', orientation='h', \n             width=700, height=700,color='Common_words')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:53.029567Z","iopub.execute_input":"2023-08-05T14:47:53.029989Z","iopub.status.idle":"2023-08-05T14:47:53.144795Z","shell.execute_reply.started":"2023-08-05T14:47:53.029950Z","shell.execute_reply":"2023-08-05T14:47:53.143872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tree of the most common words\nfig = px.treemap(temp, path=['Common_words'], values='count',title='Tree of Most Common Words')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:53.146244Z","iopub.execute_input":"2023-08-05T14:47:53.146610Z","iopub.status.idle":"2023-08-05T14:47:53.219707Z","shell.execute_reply.started":"2023-08-05T14:47:53.146571Z","shell.execute_reply":"2023-08-05T14:47:53.218865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"comment_words = '' \nstopwords = set(STOPWORDS) \n  \n# iterate through the csv file \nfor val in df.text: \n      \n    # typecaste each val to string \n    val = str(val) \n  \n    # split the value \n    tokens = val.split() \n      \n    # Converts each token into lowercase \n    for i in range(len(tokens)): \n        tokens[i] = tokens[i].lower() \n      \n    comment_words += \" \".join(tokens)+\" \"\n  \nwordcloud = WordCloud(width = 800, height = 800, \n                background_color ='white', \n                stopwords = stopwords, \n                min_font_size = 10).generate(comment_words) \n  \n# plot the WordCloud image                        \nplt.figure(figsize = (8, 8), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \n  \nplt.show() ","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:47:53.221363Z","iopub.execute_input":"2023-08-05T14:47:53.221979Z","iopub.status.idle":"2023-08-05T14:48:02.522734Z","shell.execute_reply.started":"2023-08-05T14:47:53.221934Z","shell.execute_reply":"2023-08-05T14:48:02.521840Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Positive Wordcloud","metadata":{}},{"cell_type":"code","source":"comment_words = '' \nstopwords = set(STOPWORDS) \n  \ndf_positive = df[df[\"Sentiment\"]== \"Positive\"] \n# iterate through the csv file \nfor val in df_positive.text: \n      \n    # typecaste each val to string \n    val = str(val) \n  \n    # split the value \n    tokens = val.split() \n      \n    # Converts each token into lowercase \n    for i in range(len(tokens)): \n        tokens[i] = tokens[i].lower() \n      \n    comment_words += \" \".join(tokens)+\" \"\n  \nwordcloud = WordCloud(width = 800, height = 800, \n                background_color ='white', \n                stopwords = stopwords, \n                min_font_size = 10).generate(comment_words) \n  \n# plot the WordCloud image                        \nplt.figure(figsize = (8, 8), facecolor = \"green\") \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \n  \nplt.show() ","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:48:02.524339Z","iopub.execute_input":"2023-08-05T14:48:02.524893Z","iopub.status.idle":"2023-08-05T14:48:07.883348Z","shell.execute_reply.started":"2023-08-05T14:48:02.524853Z","shell.execute_reply":"2023-08-05T14:48:07.881678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"comment_words = '' \nstopwords = set(STOPWORDS) \n  \ndf_negative = df[df[\"Sentiment\"]== \"Negative\"] \n# iterate through the csv file \nfor val in df_negative.text: \n      \n    # typecaste each val to string \n    val = str(val) \n  \n    # split the value \n    tokens = val.split() \n      \n    # Converts each token into lowercase \n    for i in range(len(tokens)): \n        tokens[i] = tokens[i].lower() \n      \n    comment_words += \" \".join(tokens)+\" \"\n  \nwordcloud = WordCloud(width = 800, height = 800, \n                background_color ='white', \n                stopwords = stopwords, \n                min_font_size = 10).generate(comment_words) \n  \n# plot the WordCloud image                        \nplt.figure(figsize = (8, 8), facecolor = \"red\") \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \n  \nplt.show() ","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:48:07.884918Z","iopub.execute_input":"2023-08-05T14:48:07.885520Z","iopub.status.idle":"2023-08-05T14:48:12.483005Z","shell.execute_reply.started":"2023-08-05T14:48:07.885466Z","shell.execute_reply":"2023-08-05T14:48:12.482134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"comment_words = '' \nstopwords = set(STOPWORDS) \n  \ndf_neutral = df[df[\"Sentiment\"]== \"Neutral\"] \n# iterate through the csv file \nfor val in df_positive.text: \n      \n    # typecaste each val to string \n    val = str(val) \n  \n    # split the value \n    tokens = val.split() \n      \n    # Converts each token into lowercase \n    for i in range(len(tokens)): \n        tokens[i] = tokens[i].lower() \n      \n    comment_words += \" \".join(tokens)+\" \"\n  \nwordcloud = WordCloud(width = 800, height = 800, \n                background_color ='white', \n                stopwords = stopwords, \n                min_font_size = 10).generate(comment_words) \n  \n# plot the WordCloud image                        \nplt.figure(figsize = (8, 8), facecolor = \"yellow\") \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \n  \nplt.show() ","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:48:12.484311Z","iopub.execute_input":"2023-08-05T14:48:12.484867Z","iopub.status.idle":"2023-08-05T14:48:17.700670Z","shell.execute_reply.started":"2023-08-05T14:48:12.484827Z","shell.execute_reply":"2023-08-05T14:48:17.699818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del df_neutral\ndel df_positive\ndel df_negative","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:48:17.702148Z","iopub.execute_input":"2023-08-05T14:48:17.702703Z","iopub.status.idle":"2023-08-05T14:48:17.711292Z","shell.execute_reply.started":"2023-08-05T14:48:17.702651Z","shell.execute_reply":"2023-08-05T14:48:17.709180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nfrom textblob import TextBlob, Word, Blobber","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:48:17.713274Z","iopub.execute_input":"2023-08-05T14:48:17.713966Z","iopub.status.idle":"2023-08-05T14:48:17.728734Z","shell.execute_reply.started":"2023-08-05T14:48:17.713901Z","shell.execute_reply":"2023-08-05T14:48:17.728062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tweet = \"I would love to watch the magic show again\"\nTextBlob(tweet).sentiment ","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:48:17.730288Z","iopub.execute_input":"2023-08-05T14:48:17.730768Z","iopub.status.idle":"2023-08-05T14:48:17.740959Z","shell.execute_reply.started":"2023-08-05T14:48:17.730726Z","shell.execute_reply":"2023-08-05T14:48:17.740003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tweet = \"special\"\nTextBlob(tweet).sentiment","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:48:17.743422Z","iopub.execute_input":"2023-08-05T14:48:17.744011Z","iopub.status.idle":"2023-08-05T14:48:17.753186Z","shell.execute_reply.started":"2023-08-05T14:48:17.743968Z","shell.execute_reply":"2023-08-05T14:48:17.752226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Applying on dataset\ndf['TB_score']= df.text.apply(lambda x: TextBlob(x).sentiment)\ndf.head()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-08-05T14:48:17.754481Z","iopub.execute_input":"2023-08-05T14:48:17.754862Z","iopub.status.idle":"2023-08-05T14:48:37.003774Z","shell.execute_reply.started":"2023-08-05T14:48:17.754823Z","shell.execute_reply":"2023-08-05T14:48:37.002852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['TB_sentiment'] = df['text'].apply(lambda x: TextBlob(x).sentiment[0])\ndf.head()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-08-05T14:48:37.005395Z","iopub.execute_input":"2023-08-05T14:48:37.005869Z","iopub.status.idle":"2023-08-05T14:48:54.305892Z","shell.execute_reply.started":"2023-08-05T14:48:37.005826Z","shell.execute_reply":"2023-08-05T14:48:54.304936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install NRCLex","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-08-05T14:48:54.307397Z","iopub.execute_input":"2023-08-05T14:48:54.307800Z","iopub.status.idle":"2023-08-05T14:49:01.372419Z","shell.execute_reply.started":"2023-08-05T14:48:54.307751Z","shell.execute_reply":"2023-08-05T14:49:01.371476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install NRCLex==2.0.2","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:49:01.374028Z","iopub.execute_input":"2023-08-05T14:49:01.374450Z","iopub.status.idle":"2023-08-05T14:49:08.454938Z","shell.execute_reply.started":"2023-08-05T14:49:01.374402Z","shell.execute_reply":"2023-08-05T14:49:08.453863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nrclex import NRCLex","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-08-05T14:49:08.458220Z","iopub.execute_input":"2023-08-05T14:49:08.458521Z","iopub.status.idle":"2023-08-05T14:49:08.463183Z","shell.execute_reply.started":"2023-08-05T14:49:08.458493Z","shell.execute_reply":"2023-08-05T14:49:08.462211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tweet = NRCLex('Good work to the team')\n#Return affect dictionary\nprint(tweet.affect_dict)\n#Return raw emotional counts\nprint(\"\\n\",tweet.raw_emotion_scores)\n#Return highest emotions\nprint(\"\\n\", tweet.top_emotions)\n#Return affect frequencies\nprint(\"\\n\",tweet.affect_frequencies)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:49:08.464709Z","iopub.execute_input":"2023-08-05T14:49:08.465123Z","iopub.status.idle":"2023-08-05T14:49:08.478739Z","shell.execute_reply.started":"2023-08-05T14:49:08.465086Z","shell.execute_reply":"2023-08-05T14:49:08.477620Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = NRCLex(\"Congratulations \")\n# Getting top emotions\nprint(\"\\n\", text.top_emotions)\n# Getting the top most emotion\nprint(\"\\n\", text.top_emotions[0][0])\n# Getting the top most emotion score\nprint(\"\\n\", text.top_emotions[0][1])","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-08-05T14:49:08.480122Z","iopub.execute_input":"2023-08-05T14:49:08.480564Z","iopub.status.idle":"2023-08-05T14:49:08.490351Z","shell.execute_reply.started":"2023-08-05T14:49:08.480515Z","shell.execute_reply":"2023-08-05T14:49:08.489046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = NRCLex(\"We can do it \")\n# Getting top emotions\nprint(\"\\n\", text.top_emotions)\n# Getting the top most emotion\nprint(\"\\n\", text.top_emotions[0][0])\n# Getting the top most emotion score\nprint(\"\\n\", text.top_emotions[0][1])","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:49:08.492490Z","iopub.execute_input":"2023-08-05T14:49:08.493069Z","iopub.status.idle":"2023-08-05T14:49:08.503243Z","shell.execute_reply.started":"2023-08-05T14:49:08.493029Z","shell.execute_reply":"2023-08-05T14:49:08.502229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def emotion(x):\n    text = NRCLex(x)\n    if text.top_emotions[0][1] == 0.0:\n        return \"No emotion\"\n    else:\n        return text.top_emotions[0][0]\ndf['Emotion'] = df['text'].apply(emotion)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:49:08.504792Z","iopub.execute_input":"2023-08-05T14:49:08.505384Z","iopub.status.idle":"2023-08-05T14:49:51.369877Z","shell.execute_reply.started":"2023-08-05T14:49:08.505343Z","shell.execute_reply":"2023-08-05T14:49:51.368995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\nfrom math import log10\n\ndf_chart = df[df.Emotion != \"No emotion\"]\nlabels = df_chart.Emotion.value_counts().index.tolist()\ndata = df_chart.Emotion.value_counts()\n#number of data points\nn = len(data)\n#find max value for full ring\nk = 10 ** int(log10(max(data)))\nm = k * (1 + max(data) // k)\n\n#radius of donut chart\nr = 1.5\n#calculate width of each ring\nw = r / n \n\n#create colors along a chosen colormap\ncolors = [cm.terrain(i / n) for i in range(n)]\n\n#create figure, axis\nfig, ax = plt.subplots()\nax.axis(\"equal\")\n\n#create rings of donut chart\nfor i in range(n):\n    #hide labels in segments with textprops: alpha = 0 - transparent, alpha = 1 - visible\n    innerring, _ = ax.pie([m - data[i], data[i]], radius = r - i * w, startangle = 90, labels = [\"\", labels[i]], labeldistance = 1 - 1 / (1.5 * (n - i)), textprops = {\"alpha\": 0}, colors = [\"white\", colors[i]])\n    plt.setp(innerring, width = w, edgecolor = \"white\")\n\nplt.legend()\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-08-05T14:49:51.371285Z","iopub.execute_input":"2023-08-05T14:49:51.371682Z","iopub.status.idle":"2023-08-05T14:49:51.626929Z","shell.execute_reply.started":"2023-08-05T14:49:51.371644Z","shell.execute_reply":"2023-08-05T14:49:51.626024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"b = df_chart.Emotion.value_counts().index.tolist()\na = df_chart.Emotion.value_counts(normalize = True).tolist()\nrow = pd.DataFrame({'scenario' : []})\nrow[\"scenario\"] = b\nrow[\"Percentage\"] = a\nfig = px.treemap(row, path= [\"scenario\"], values=\"Percentage\",title='Tree of Emotions')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:49:51.628322Z","iopub.execute_input":"2023-08-05T14:49:51.628834Z","iopub.status.idle":"2023-08-05T14:49:51.721902Z","shell.execute_reply.started":"2023-08-05T14:49:51.628791Z","shell.execute_reply":"2023-08-05T14:49:51.721012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['sentiment']='Neutral'\ndf.loc[(df['TB_sentiment']==0),'sentiment']='Neutral'\ndf.loc[(df['TB_sentiment']>0),'sentiment']='Positive'\ndf.loc[(df['TB_sentiment']<0),'sentiment']='Negative'","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:52:07.645351Z","iopub.execute_input":"2023-08-05T14:52:07.645710Z","iopub.status.idle":"2023-08-05T14:52:07.681444Z","shell.execute_reply.started":"2023-08-05T14:52:07.645678Z","shell.execute_reply":"2023-08-05T14:52:07.680623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:54:12.790621Z","iopub.execute_input":"2023-08-05T14:54:12.790991Z","iopub.status.idle":"2023-08-05T14:54:12.845026Z","shell.execute_reply.started":"2023-08-05T14:54:12.790956Z","shell.execute_reply":"2023-08-05T14:54:12.843682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Accuracy for e-commerce_dataset\n# from sklearn.metrics import classification_report\n# y_true = df['sentiment']\n# y_pred = df['Sentiment']\n# target_names = ['Positive', 'Negative', 'Neutral']\n# print(classification_report(y_true, y_pred, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:55:44.313483Z","iopub.execute_input":"2023-08-05T14:55:44.313830Z","iopub.status.idle":"2023-08-05T14:55:44.318266Z","shell.execute_reply.started":"2023-08-05T14:55:44.313797Z","shell.execute_reply":"2023-08-05T14:55:44.317001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classification_report for covid dataset\n# from sklearn.metrics import classification_report\n# y_true = df['sentiment']\n# y_pred = df['Sentiment']\n# target_names = ['Positive', 'Negative', 'Neutral']\n# print(classification_report(y_true, y_pred, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:55:40.639027Z","iopub.execute_input":"2023-08-05T14:55:40.639392Z","iopub.status.idle":"2023-08-05T14:55:40.645016Z","shell.execute_reply.started":"2023-08-05T14:55:40.639360Z","shell.execute_reply":"2023-08-05T14:55:40.644009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}